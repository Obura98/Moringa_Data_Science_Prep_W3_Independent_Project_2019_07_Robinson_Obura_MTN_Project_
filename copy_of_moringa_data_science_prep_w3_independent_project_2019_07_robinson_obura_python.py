# -*- coding: utf-8 -*-
"""Copy of Moringa_Data_Science_Prep_W3_Independent_Project_2019_07_Robinson_Obura_Python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K0zTN83JF7xveuvyjKZfYWe0GWZhLkt-
"""

#Importing Pandas and Numpy Library
import pandas as pd
import numpy as np

#Loading our datasets
#Url to excel sheet
url="/CDR_description.xlsx"
df = pd.read_excel(url)
df

#Url to excel sheet
url="/cells_geo_description.xlsx"
df = pd.read_excel(url)
df

#loading our csv files
url="/cells_geo.csv"
df = pd.read_csv(url, delimiter=';')
df

url1="/Telcom_dataset.csv"

df1 = pd.read_csv(url1, )
df1.head()
#changing PRODUTC to PRODUCT
df1.columns=['PRODUCT','VALUE', 'DATETIME','CELL_ON_SITE','DW_A_NUMBER_INT','DW_B_NUMBER_INT','COUNTRY_A','COUNTRY_B','CELL_ID','SITE_ID']
df1
#checking for duplicates and deleting them
df1.duplicated()
df.drop_duplicates()
#checking for missing values and deleting them
df1.isnull()
df1.dropna()

url2="/Telcom_dataset2.csv"

df2 = pd.read_csv(url2)
df2.columns=['PRODUCT','VALUE', 'DATETIME','CELL_ON_SITE','DW_A_NUMBER_INT','DW_B_NUMBER_INT','COUNTRY_A','COUNTRY_B','CELL_ID','SITE_ID']
df2
#checking for duplicates and deleting them
df2.duplicated()
df2.drop_duplicates()
#checking for missing values and deleting them
df2.isnull()
df2.dropna()

url3="/Telcom_dataset2.csv"
df3 = pd.read_csv(url3)
df3.columns=['PRODUCT','VALUE', 'DATETIME','CELL_ON_SITE','DW_A_NUMBER_INT','DW_B_NUMBER_INT','COUNTRY_A','COUNTRY_B','CELL_ID','SITE_ID']
df3
#checking for duplicates and deleting them
df3.duplicated()
df3.drop_duplicates()
#checking for missing values and deleting them
df3.isnull()
df3.dropna()

#Merging datasets telecom datasets 1,2 and 3
df_col = [df1, df2, df3]
df_all = pd.concat(df_col)
df_all.head()

#joining our new joined dataframe with the cells_geo dataframe=df
df_all.drop_duplicates(subset=['CELL_ID'], inplace=True) 
df.merge(df_all, how='left', on='CELL_ID' )

df_col_new = [df,df1, df2, df3]
df_new = pd.concat(df_col_new)

df_new.head()
#checking for duplicates and deleting them
df_new.duplicated()
df_new.drop_duplicates()
#checking for missing values and deleting them
#df_new.isnull()
#df3.dropna()
#df.head(10)

#Which ones were the most used city for the three days?
import datetime 

df_all['VILLES'].value_counts()

#Which cities were the most used during business and home hours?
df_all['VILLES','DATETIME'].value_counts()

#Most used city for the three days?
df_all